import cv2
import json
import os
import subprocess
import sys
import time
import csv  # æ–°å¢
from utils import *  # æ–°å¢
from PIL import Image, ImageDraw, ImageFont  # æ–°å¢
import numpy as np  # æ–°å¢
import pandas as pd  # æ–°å¢



class VideoAnnotator:
    def __init__(self, video_name, output_path="output/", segment_duration=3):

        self.video_path = os.path.join("video/", video_name)
        self.converted_audio_path = os.path.join("converted_audio/", video_name.replace(".mkv", "_converted.mp3"))
        self.converted_video_path = os.path.join("converted_video/", video_name.replace(".mkv", "_converted.mp4"))
        self.output_file = get_unique_filename(os.path.join(output_path, video_name.replace(".mkv", ".json")))

        self.segment_duration = segment_duration
        self.annotations = []
        self.cap = None
        self.segment_index = 0  # **æ–°å˜é‡ï¼šç¡®ä¿æ—¶é—´æ­£ç¡®**
        self.video_duration = 0  # **æ–°å˜é‡ï¼šå­˜å‚¨è§†é¢‘æ€»æ—¶é•¿**

        # **æƒ…ç»ªæ ‡ç­¾å®šä¹‰ï¼ˆå¸¦ Emojiï¼‰**
        self.emotion_labels = [
            "Serenity", "Calm", "Relaxed",
            "Neutrality", "Focused", "Active", "Excited",
            "Agitated", "Overstimulated", "Explosive"
        ]

    def draw_emotion_labels(self, frame):
        """åœ¨è§†é¢‘å·¦ä¾§ç»˜åˆ¶æƒ…ç»ªæ ‡ç­¾ï¼Œä½¿ç”¨ç»Ÿä¸€çš„èƒŒæ™¯"""
        x, y = 20, 40  # **å·¦ä¸Šè§’èµ·å§‹ä½ç½®**
        box_width, box_height = 220, 40  # **åŠ å¤§æ ‡ç­¾å¤§å°**
        spacing = 8  # **æ ‡ç­¾é—´è·**
        total_height = len(self.emotion_labels) * (box_height + spacing)  # **è®¡ç®—æ€»èƒŒæ™¯é«˜åº¦**
        
        # **è½¬æ¢ OpenCV å›¾åƒä¸º PIL**
        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(frame_pil)

        # **ç»˜åˆ¶æ•´ä½“èƒŒæ™¯æ¡†**
        background_top_left = (x, y)
        background_bottom_right = (x + box_width, y + total_height)
        draw.rectangle([background_top_left, background_bottom_right], fill=(80, 80, 80, 220))  # **æ›´äº®çš„åŠé€æ˜èƒŒæ™¯**

        # **å°è¯•åŠ è½½ä¸åŒå­—ä½“**
        font_paths = [
            "/usr/share/fonts/truetype/noto/NotoColorEmoji.ttf",
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
            "Arial.ttf"
        ]

        font = None
        for font_path in font_paths:
            try:
                font = ImageFont.truetype(font_path, 28)
                # print(f"âœ… ä½¿ç”¨å­—ä½“: {font_path}")
                break
            except:
                continue

        if font is None:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
            font = ImageFont.load_default()

        for i, label in enumerate(self.emotion_labels):
            text_position = (x + 10, y + i * (box_height + spacing) + 15)
            draw.text(text_position, f"{i} - {label}", font=font, fill=(255, 255, 255, 255))

        # **è½¬æ¢å› OpenCV å›¾åƒ**
        frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)
        return frame

    def check_csv_length(self):
        """æ£€æŸ¥ CSV æ–‡ä»¶é•¿åº¦æ˜¯å¦ç¬¦åˆè¦æ±‚"""
        if not os.path.exists(self.output_file):
            return 0
        with open(self.output_file, "r") as f:
            data = json.load(f)
            return len(data)
    
    def start_annotation(self):
        """å¼€å§‹æ’­æ”¾è§†é¢‘å¹¶è¿›è¡Œæ ‡æ³¨"""
        mkv_to_mp4(self.video_path, self.converted_video_path)
        extract_audio(self.video_path, self.converted_audio_path)
        self.cap = cv2.VideoCapture(self.converted_video_path)

        if not self.cap.isOpened():
            print("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ï¼")
            sys.exit(1)

        total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        frame_rate = int(self.cap.get(cv2.CAP_PROP_FPS))  # è®¡ç®— FPS
        self.video_duration = total_frames / frame_rate  # **è®¡ç®—è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰**
        print(f"è§†é¢‘æ€»æ—¶é•¿: {self.video_duration:.2f} ç§’, FPS: {frame_rate}")


        while True:
            # **ä¿®æ­£ start_timeï¼Œç¡®ä¿æ˜¯æ ‡å‡†é—´éš”**
            start_time = self.segment_index * self.segment_duration
            segment_end_time = start_time + self.segment_duration
            
             # **æ£€æµ‹æ˜¯å¦è¶…è¿‡è§†é¢‘æ—¶é•¿ï¼Œè¶…å‡ºåˆ™é€€å‡º**
            if start_time >= self.video_duration:
                print("ğŸ¬ è§†é¢‘æ’­æ”¾å®Œæˆï¼Œæ ‡æ³¨ç»“æŸï¼")
                self.exit_and_save()

            print(f"æ’­æ”¾ç‰‡æ®µ {start_time:.2f}s - {segment_end_time:.2f}s")

            # **ç¡®ä¿è§†é¢‘è·³è½¬åˆ°æ­£ç¡®çš„æ—¶é—´**
            self.cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)

            # **å¯åŠ¨éŸ³é¢‘**
            audio_process = subprocess.Popen(
                ["ffplay", "-nodisp", "-autoexit", "-ss", str(start_time), "-t", str(self.segment_duration), self.converted_audio_path],
                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
            )

            # **åŒæ­¥æ’­æ”¾è§†é¢‘**
            video_start_time = time.time()
            while self.cap.get(cv2.CAP_PROP_POS_MSEC) / 1000 < segment_end_time:
                ret, frame = self.cap.read()
                if not ret:
                    break
                
                frame = self.draw_emotion_labels(frame)  # **ç»˜åˆ¶æƒ…ç»ªæ ‡ç­¾**
                cv2.imshow("Annotation Tool", frame)

                elapsed_time = time.time() - video_start_time
                video_elapsed = self.cap.get(cv2.CAP_PROP_POS_MSEC) / 1000 - start_time
                if video_elapsed > elapsed_time:
                    time.sleep(video_elapsed - elapsed_time)

                key = cv2.waitKey(int(1000 / frame_rate)) & 0xFF
                if key == ord('q'):
                    self.exit_and_save()
                elif key == ord('r'):  # **é‡æ’­**
                    self.cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)
                    audio_process.kill()  # **åœæ­¢éŸ³é¢‘**
                    break  # **é€€å‡ºæ’­æ”¾å¾ªç¯ï¼Œé‡æ–°æ’­æ”¾**

            # **ç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæ¯•**
            audio_process.wait()

            # **ç­‰å¾…ç”¨æˆ·æ‰“åˆ†**
            print("è¯·æ‰“åˆ† (0-9)ï¼ŒæŒ‰ 'q' é€€å‡ºï¼ŒæŒ‰ 'r' é‡æ–°æ’­æ”¾:")
            while True:
                key = cv2.waitKey(0) & 0xFF
                if ord('0') <= key <= ord('9'):
                    self.annotations.append({"timestamp": start_time, "arousal": key - ord('0')})
                    self.segment_index += 1  # **æ­£ç¡®æ¨è¿›åˆ°ä¸‹ä¸€ä¸ªç‰‡æ®µ**
                    break
                elif key == ord('q'):
                    self.exit_and_save()
                elif key == ord('r'):  # **ç”¨æˆ·æƒ³é‡æ’­**
                    self.cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)
                    break  # **è·³å‡ºæ‰“åˆ†å¾ªç¯ï¼Œé‡æ’­å½“å‰ç‰‡æ®µ**

    def exit_and_save(self):
        """é€€å‡ºç¨‹åºå¹¶ä¿å­˜æ ‡æ³¨æ•°æ®"""
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()

        with open(self.output_file, "w") as f:
            json.dump(self.annotations, f, indent=4)
        
        self.save_annotations_to_csv()  # æ–°å¢

        print(f"æ ‡æ³¨å®Œæˆï¼æ•°æ®å·²ä¿å­˜åˆ° {os.path.join("data/", self.output_file)}")
        sys.exit(0)

    def save_annotations_to_csv(self):
        """å°†æ ‡æ³¨æ•°æ®ä¿å­˜ä¸º CSV æ–‡ä»¶"""
        csv_file = get_unique_filename(self.output_file.replace(".json", ".csv"))
        with open(csv_file, mode='w', newline='') as file:
            writer = csv.writer(file)
            writer.writerow(["timestamp", "arousal"])
            for annotation in self.annotations:
                writer.writerow([annotation["timestamp"], annotation["arousal"]])
        print(f"æ ‡æ³¨æ•°æ®å·²ä¿å­˜åˆ° {csv_file}")


if __name__ == "__main__":
    # ä½¿ç”¨ VideoAnnotator ç±»
    # video_name = "rgb_lhb_game_session.mkv"
    # annotator = VideoAnnotator(video_name, segment_duration=3)
    # annotator.start_annotation()

    # # data extension checker
    # check_and_extend_csv("output/rgb_byz_game_session.csv", segment_duration=3)
    # check_and_extend_csv("output/rgb_byz_baseline.csv", segment_duration=3)

    # data interpolation
    input_csv_file = "output/rgb_byz_game_session.csv"  # ä½ çš„åŸå§‹ CSV æ–‡ä»¶
    output_csv_file = input_csv_file.replace(".csv", "_interpolated.csv")
    interpolate_csv(input_csv_file, output_csv_file, target_interval=1, visualize=True, method="linear")  # spline
    visualize_interpolation(input_csv_file, output_csv_file)

